\documentclass{article}
\usepackage{graphicx}
\usepackage[ampersand]{easylist}
\usepackage{fullpage}
\usepackage{url}

\begin{document}

\title{Deliverables Summary}
\author{Michael McDonnell}

\maketitle
\section*{Introduction}

The thesis focus for the year was attempting to develop a system to allow a self driving vehicle to identify road features to set the conditions for navigation through features such as intersections.

The development attempted to follow an AGILE approach with iterative increases in functionality. A simulation system was developed to provide camera feed inputs to a Python process. The core deliverables discussed were:
\begin{easylist}[itemize]
	& \textbf{Journal or Conference paper.}
	& \textbf{Simulation with Inter Process Communication.}
	& \textbf{Navigation localisation system.}
\end{easylist}

During the course of development familiarity was gained in a range of additional areas. Edge detection was investigated as an initial road detection attempt and the use of convolutional neural networks was investigated as an alternate option. As a result of this work outside the core system, the following additional deliverables have been developed:
\begin{easylist}[itemize]
	& \textbf{MATLAB assignment resources for Computational Problem Solving.} 
	& \textbf{Sprint review example.} 
	& \textbf{???Machine learning familiarisation activities}
\end{easylist}



\section{Journal or Conference Paper}

It was identified that \textit{Robotics and Autonomous Systems} is a suitable journal to submit a paper to. This journal deals with the core subject material, has an impact factor of 2.928 and has a clearly detailed submission process. If the paper is not accepted into this journal alternative options will be considered including conferences including optimistically, the 17th International Conference on Ubiquitous Robots (UR 2020) - Kyoto with a submission date of early 2020. A more flexible option is one of the various International Conferences on Control, Automation, Robotics and Vision Engineering throughout 2020.

The initial draft is aligned to the Robotics and Autonomous systems general format however content, style and length can be massaged based on submission target.

\section{Simulation with Inter Process Communication}

\textbf{TODO: Intro, tidying up and commenting, documentation, extensions}

\section{Navigation localisation system}

The provided system includes test data for a proof of concept. In addition to the provided files, \textbf{cv2} and \textbf{numpy} are both required. Provided files are as follows:

\begin{easylist}[itemize]
	& \textit{nav\_localisation.py -} This is the core file which is run. The default method here calls a single \textit{main} method and passes test data (see below). The main work in this script is from the \textit{process\_frame} method which maintains a simple state using boolean flags to determine if detection or tracking code is run. This script also contains visualisation code as well as video saving function.
	& \textit{road\_surface\_detection.py -} Class to use as a road detector, implements Histogram backprojection road surface detection. \textit{get\_road\_surface\_from\_new\_frame} is the Class method called to detect the road surface in a new frame.
	& \textit{feature\_tracker.py -} Obtain initial feature mask using \textit{get\_feature\_masks} and check for feature detection using \textit{check\_feature}. This includes argument for optical flow which is estimated using \textit{GetUpdatedRoadFeatureLocationFarneback}.
	& \textit{bezier.py -} Helper script to develop bezier curve mask using \textit{get\_curve\_mask}. Generic in that \textit{draw\_bezier} can be called directly to draw bezier curve to any image.
	& \textit{test\_data.py -} Implements the data interface required (see following subsection) and contains test methods to confirm data.
\end{easylist}


\subsection{Data interface}

The system expects a data interface with the following methods:

\begin{easylist}[itemize]
	& \textit{get\_next\_feature() -} Returns next feature or None if no more available.
	& \textit{get\_next\_frame() -}	Returns next image frame (either from video stream or saved images).
	& \textit{get\_inverse\_perspective\_matrix() -} Returns the inverse perspective matrix developed for this dataset.
	& \textit{get\_ipm\_mask() -} Returns a mask which defines the area of information for the inverse perspective matrix.
\end{easylist}

The provided code demonstrates the concept of the system and is suitable for extension, generalisation and improvement. Any script that implements the data interface can be passed to the main method in \textit{nav\_localisation.py} for processing which allows easy implementation of multiple different input source files. The data interface provided uses images and an inverse perspective transformation matrix included in the \textit{TestData} subfolder. 


\section{MATLAB assignment resources for Computational Problem Solving}

It was identified that filter convolution is a (relatively) simple algorithm to implement and may be a suitable teaching case for a practical implementation of loops. In lieu of developing a specific assignment, a set of relatively simple set of convolution operations using functions over several files is included as a starting point for an assignment.

The files include operations on two images using a combination of smoothing (blur) and median filters as well as edge hardening (subtracting smoothed image from original image) and masking. These algorithms have been implemented naively using nested loops with helper functions to ensure the logic is as clear as possible. Helper functions include getting a filtered value (filtering a single point involves two nested loops) and a `safe getter' which will return a value or 0 if a coordinate is out of bounds.

\begin{easylist}[itemize]
	& \textbf{Images.mat} - MATLAB variable file with both images saved.
	& \textbf{ProcessImages.m} - Base file to run to demonstrate operations on both images. Assuming data has been loaded from \textbf{Images.mat}, the following files can be run for individual demonstrations:
	&& \textbf{FarmImage.m}
	&& \textbf{CountrysideImage.m}

	& Core files:
	&& \textbf{RunFilter.m} - Apply a convolution filter to an image using nested for loops. 
	&& \textbf{MedianFilter.m} - Apply a median filter to an image. Median filter sets the new pixel value to the median value over the filter size about the point. This is very usefeul for the removal of 'salt and pepper' noise.
	
	& Helper files:
	&& \textbf{ValueFromFilterCoord.m} - Get a single convolution value for a pixel. This function applies the convolution filter about a location on the image defined by an x, y coordinate.
	&& \textbf{Threshold.m} - Simple thresholding function implemented as nested loops with conditionals. Thresholding returns a binary image (black and white) where pixels of value greater than the threshold will be white and lower than a threshold will be black.
	&& \textbf{NormaliseImage.m} - Helper function to normalise an image from 8 bit to floating point between 0 and 1.
	&& \textbf{MedianFromCoord.m} - Helper function to return the median value within a provided filter size (x and y) about a point. 
	&& \textbf{GetValueOrZero.m} - Helper function to 'safely get' a value within a matrix. If the provided coordinates fall outside the matrix dimensions, return 0 instead.
	&& \textbf{MaskFilter.m} - Helper function to mask out all elements of an image outside a provided rectangle bounds.
\end{easylist}

These files represent a verbose loop based implementation of simple image processing. A possible assignment task is to provide these files with portions and/or full implementations missing. As an example the core files could be provided without the loops implemented and files such as \textbf{GetValueOrZero.m} could be provided without any implementation code to be filled out. The exact task is dependant on the level of expected competency of students. Extensions to this task could involve improving the implementation, for example the \textbf{conv2} function (\url{https://au.mathworks.com/help/matlab/ref/conv2.html}) can replace the majority of core and helper files. Providing a hint that 2D convolution is the task they are undertaking would allow exercising of documentation research (while being simple enough that googling `MATLAB 2d convolution' would lead to the answer).

\section{Sprint review example.}

The feature development of the system and simulation was managed using an AGILE approach. This involved incremental feature delivery with a fortnightly review. Fortnightly reviews included triaging of future work but also the provision of an update to interested stakeholders. The review includes the `velocity' over the previous fortnight which is a quantified measure of work based off the estimated `story points' per task that were completed in the sprint. Following this a presentation of the current capability (generally focussing on impactful demonstrations of new features developed) occurs and discussion with stakeholders. After the sprint review, tasks are selected for work over the following fortnight based off the existing velocity. This assists with planning time allocations (using existing knowledge to estimate small task difficulty) while retaining flexibility to rapidly pivot in focus.

The sprint reviews throughout the year morphed into an informal brief review due to the difficulty in locking in standing appointments however the theory was maintained. An example of a formal sprint review is included as an example to individuals in future that may be interested in adopting this approach and are looking for a starting point.

\section{???Machine learning familiarisation activities}

The use of Convolutional Neural Networks (CNN) for road surface detection was seriously considered. As part of analysing the potential effectiveness of this solution an effort was made to develop a robust understanding of neural network (and more generally, machine learning algorithms) implementation from first principles as well as small `toy' projects to gain a working familiarity with implementation details. A focus on interpretable AI and a desire to have a more complete solution (with driving lines and intersection tracking) meant that a CNN approach was not pursued however a good understanding of the application was developed.

The Stanford University online Machine Learning course was undertaken which provided a mathematical understanding of multiple machine learning algorithms. The certificate of completion of this is included. On completion of this course familiarisation projects were developed using Python and Keras which is a Tensorflow wrapper. 

\textbf{TODO: Projects undertaken}
\textbf{TODO: How they work}



\textbf{TODO: Wording of this deliverable title}
\section*{Final words}
The project this year was ambitious, challenging and allowed development of conceptual understanding over a range of topics. In addition to the core academic deliverable requirements it is hoped that some of the additional delivered elements may assist others in delving deeper into some of these topics.


%	\begin{figure}
%		\centering
%		\includegraphics[width=3.0in]{myfigure}
%		\caption{Simulation Results}
%		\label{simulationfigure}
%	\end{figure}

\end{document}